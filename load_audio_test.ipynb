{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIEtGtIWNKN7cjXPtVIjdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaarimu/whisper_swahili/blob/main/load_audio_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the whisper model"
      ],
      "metadata": {
        "id": "ql5gCqIVDYcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVjtLQOC-bv",
        "outputId": "dd9736f2-bcb5-4e61-e15c-cdf42cc0403f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-k30z41lg\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-k30z41lg\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 1.8 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=71930bb7bbdc0f7cc0ce3f172bafc9ed98038b3c13f36cb30ebecb2625ff7c0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra4kqcmk/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whisper needs ffmpeg installed on the current machine to work"
      ],
      "metadata": {
        "id": "oJXpPap1Di1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "irm get.scoop.sh | iex\n",
        "scoop install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "0_meckthDgE1",
        "outputId": "37a7cb44-fc52-4cba-ebc5-fb475036b8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-74b4da314bc6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    irm get.scoop.sh | iex\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "irm get.scoop.sh | iex\n",
        "# You can use proxies if you have network trouble in accessing GitHub, e.g.\n",
        "irm get.scoop.sh -Proxy 'http://<ip:port>' | iex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "83oORw9TLZlg",
        "outputId": "e56087c1-aa07-4294-e1a6-8bca3f9f06b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-0f96af4153a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    irm get.scoop.sh | iex\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary packages"
      ],
      "metadata": {
        "id": "NyDFhlbdDxQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "KWuYLAo2Do8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a GPU is the preferred way to use Whisper. The first line results False, if Cuda compatible Nvidia GPU is not available and True if it is available. The second line of code sets the model to preference GPU whenever it is available"
      ],
      "metadata": {
        "id": "h3GgxlfyEAhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "8zj5dEk_EMkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Tg6g7sB-EmU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large\", device=DEVICE)\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ_weH3KEWMt",
        "outputId": "972ec729-a76f-40de-f3b3-ed093676495b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:47<00:00, 64.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 1,541,384,960 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading audio file to transcribe"
      ],
      "metadata": {
        "id": "_2uGkHcOGxhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = whisper.load_audio(\"swahili_test.mp4\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
      ],
      "metadata": {
        "id": "agW41fndHc-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting the language of the audio"
      ],
      "metadata": {
        "id": "yGNvva2_JdL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDbj4erhHoQV",
        "outputId": "de55db6e-3b27-4771-cae3-a5fa73f7cdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: sw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribe 30 seconds of audio using decoding options and decode command"
      ],
      "metadata": {
        "id": "bQjE1d_zHu4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "options = whisper.DecodingOptions(language=\"sw\", without_timestamps=True, fp16 = False)\n",
        "result = whisper.decode(model, mel, options)\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g09U04GJ8MrJ",
        "outputId": "eb8c2930-19c7-4146-99f0-d4c48a1502e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kwa hivyo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribing whole audio file"
      ],
      "metadata": {
        "id": "q_2ESJUFH9j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"swahili_test.mp4\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckQ_taEcIETi",
        "outputId": "7dceee20-bc52-4f6d-a017-c60287362ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Na sasiku ya siku, haka reje ya mze mcheke ya mwezi, haka muita yule kijulanga, haka mwambiha, Njo! Na sikia, mjuku wangu sasa wewe unajitapa, kana kuamba wewe nimbuji mbobevu na hauna tena umamuma, unasema kiswahili mufti Haka sema, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali Na ukinijibu swali hili, ba, si, sasa, nitakuingiza katika buruji la wa swahili ni seme, naa, muanetu wame kuwa Haka mwambiha sasa, e, niambihe siku saba zijazo kwa kiswahili, kila moja Alafu, uniambihe pia siku zilizo pita saba zote kwa kiswahili Alafu, baada ya pale, nitasema narotaku nisema yule mze, haka mwambiha yule kijulanga Hasa kijulanga li popigwa le swali, haka anza kutweta Hahahahahaha, anatweta, alafu haka anza kuvanga vanga Na sika na kuamba likuwa na jimasa masa, likuwa hafahamu kabisa Hameduwa kama mtu waliopigwa na dafra ho, hametuwa macho hivi Hamekutana na mze mcheke amwezi, mswahili wa mswahili, haweketi katika buruji pa mwja na kina Sherban Robert Sasa haka mwambiha, naajua haufahamu Haka mwambiha shikilia kidi nindi, nasema leo, nasema kesho, nasema kesho kutwa Nasema mtondo, mtondogo, siku ya tano yo Alafu nasema kitondo, ni siku ya sita, alafu nasema kitodyo, ni siku ya saba Kuna kitondo, siku ya sita, alafu kitodyo, siku ya saba Awu ngino nasema kitondo jogo Kamata kamatia ezo siku, saba za wiki misha kutajia zinazo kuja Zinazo pita, hana mwambiha yule kijulanga, halijifanya kwa mba ye ni mswahili Hana mwambiha leo, alafu namambiha jana, alafu namambiha juzi, alafu namambiha majuzi Alafu namambiha juzi juzi, alafu namambiha majuzi yale, alafu nakijomba Siku ngavi, saba, juhu naweza kuzirudia ezo siku We mswahili, haka bakia maamakibi kama mtu waliopigwa na dafrao Kamambia tabu yako we mswahili, ni tabu ilea mfinyanzi kulia gaeni Ni nacho, ni nacho Kube huna, jina langu na hito Joram kumbi na ayuka huku ni kioseka kwenda wazimu Mpako wakati mungine, we badu wakatabahu fakiri, mekutajia siku saba Jilizopita na zijazo kiswaidi jina unaweza kuzirudia Kube huna, jina langu na hito Joram kumbi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn6hkL89KxAG",
        "outputId": "82387050-bdd4-40c1-a9ed-a8ff9d505986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.25.0)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.8/dist-packages (from openai) (1.5.2.221213)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.8/dist-packages (from pandas-stubs>=1.1.0.11->openai) (2022.7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import csv\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def translate(text):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=f\"translate to English: {text}\",\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F2ast_0QJc6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = (result[\"text\"])\n",
        "translated_text = translate(data)\n",
        "print(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t4h3Y3pKUks",
        "outputId": "8b077fc0-91ab-48f7-fabc-0782fc33d406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " na ayuka huku ni kioseka kwenda wazimu Mpako wakati mungine, we badu wakatabahu fakiri, mekutajia siku saba Jilizopita na zijazo kiswahili ni seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali Na ukinijibu swali hili, ba, si, sasa, nitakuingiza katika buruji la wa swahili ni seme, naa, muanetu wame kuwa Haka mwambiha sasa, e, niambihe siku saba zijazo kwa kiswahili, kila moja Alafu, uniambihe pia siku zilizo pita saba zote kwa kiswahili Alafu, baada ya pale, nitasema narotaku nisema yule mze, haka mwambiha yule kijulanga Hasa kijulanga li popigwa le swali, haka anza kutweta Hahahahahaha, anatweta, alafu haka anza kuvanga vanga Na sika na kuamba likuwa na jimasa masa, likuwa hafahamu kabisa Hameduwa kama mtu waliopigwa na dafra ho, hametuwa macho hivi Hamekutana na mze mcheke amwezi, mswahili wa mswahili, haweketi katika buruji pa mwja na kina Sherban Robert Sasa haka mwambiha, naajua haufahamu Haka mwambiha shikilia kidi nindi, nasema leo, nasema kesho, nasema kesho kutwa Nasema mtondo, mtondogo, siku ya tano yo Alafu nasema kitondo, ni siku ya sita, alafu nasema kitodyo, ni siku ya saba Kuna kitondo, siku ya sita, alafu kitodyo, siku ya saba Awu ngino nasema kitondo jogo Kamata kamatia ezo siku, saba za wiki misha kutajia zinazo kuja Zinazo pita, hana mwambiha yule kijulanga, halijifanya kwa mba ye ni mswahili Hana mwambiha leo, alafu namambiha jana, alafu namambiha juzi, alafu namambiha majuzi Alafu namambiha juzi juzi, alafu namambiha majuzi yale, alafu nakijomba Siku ngavi, saba, juhu naweza kuzirudia ezo siku We mswahili, haka bakia maamakibi kama mtu waliopigwa na dafrao Kamambia tabu yako we mswahili, ni tabu ilea mfinyanzi kulia gaeni Ni nacho, ni nacho\n",
            "\n",
            "On the day of the day, the same day of the month, the same day of the week, the same day of the year, the same Njo! And when I hear that my husband is now beating you, and if you say you're going to bring a stick and you don't have a snotty nose, you say in Kiswahili \"haka sema, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (If you don't say it, then, don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kiswahili dictionary as \"seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (Don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kiswahili dictionary as \"seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (Don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the translated text to a CSV file\n",
        "with open(\"translated_text.csv\", \"w\", newline=\"\") as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"Original text\", \"Translated text\"])\n",
        "    writer.writerow([data, translated_text])"
      ],
      "metadata": {
        "id": "7FL1lz8KRE33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Gf-2-2dpE2Pu",
        "outputId": "240f0904-4590-4e85-f095-219f7234c16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    6018 MB |    8961 MB |    7706 GB |    7700 GB |\\n|       from large pool |    6012 MB |    8952 MB |    6615 GB |    6609 GB |\\n|       from small pool |       6 MB |      72 MB |    1090 GB |    1090 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    6018 MB |    8961 MB |    7706 GB |    7700 GB |\\n|       from large pool |    6012 MB |    8952 MB |    6615 GB |    6609 GB |\\n|       from small pool |       6 MB |      72 MB |    1090 GB |    1090 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    9784 MB |    9784 MB |    9784 MB |       0 B  |\\n|       from large pool |    9708 MB |    9708 MB |    9708 MB |       0 B  |\\n|       from small pool |      76 MB |      76 MB |      76 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  216590 KB |  653448 KB |    4858 GB |    4857 GB |\\n|       from large pool |  214790 KB |  651450 KB |    3719 GB |    3719 GB |\\n|       from small pool |    1800 KB |   26016 KB |    1138 GB |    1138 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1262    |    2519    |    7755 K  |    7754 K  |\\n|       from large pool |     517    |    1033    |    1101 K  |    1101 K  |\\n|       from small pool |     745    |    1486    |    6654 K  |    6653 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1262    |    2519    |    7755 K  |    7754 K  |\\n|       from large pool |     517    |    1033    |    1101 K  |    1101 K  |\\n|       from small pool |     745    |    1486    |    6654 K  |    6653 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     477    |     477    |     477    |       0    |\\n|       from large pool |     439    |     439    |     439    |       0    |\\n|       from small pool |      38    |      38    |      38    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     137    |     311    |    3839 K  |    3839 K  |\\n|       from large pool |     132    |     306    |    1032 K  |    1032 K  |\\n|       from small pool |       5    |      46    |    2807 K  |    2807 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data, translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCgbS_-0VxMq",
        "outputId": "0f920e8a-65b0-4765-82dc-41612b1483ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Na sasiku ya siku, haka reje ya mze mcheke ya mwezi, haka muita yule kijulanga, haka mwambiha, Njo! Na sikia, mjuku wangu sasa wewe unajitapa, kana kuamba wewe nimbuji mbobevu na hauna tena umamuma, unasema kiswahili mufti Haka sema, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali Na ukinijibu swali hili, ba, si, sasa, nitakuingiza katika buruji la wa swahili ni seme, naa, muanetu wame kuwa Haka mwambiha sasa, e, niambihe siku saba zijazo kwa kiswahili, kila moja Alafu, uniambihe pia siku zilizo pita saba zote kwa kiswahili Alafu, baada ya pale, nitasema narotaku nisema yule mze, haka mwambiha yule kijulanga Hasa kijulanga li popigwa le swali, haka anza kutweta Hahahahahaha, anatweta, alafu haka anza kuvanga vanga Na sika na kuamba likuwa na jimasa masa, likuwa hafahamu kabisa Hameduwa kama mtu waliopigwa na dafra ho, hametuwa macho hivi Hamekutana na mze mcheke amwezi, mswahili wa mswahili, haweketi katika buruji pa mwja na kina Sherban Robert Sasa haka mwambiha, naajua haufahamu Haka mwambiha shikilia kidi nindi, nasema leo, nasema kesho, nasema kesho kutwa Nasema mtondo, mtondogo, siku ya tano yo Alafu nasema kitondo, ni siku ya sita, alafu nasema kitodyo, ni siku ya saba Kuna kitondo, siku ya sita, alafu kitodyo, siku ya saba Awu ngino nasema kitondo jogo Kamata kamatia ezo siku, saba za wiki misha kutajia zinazo kuja Zinazo pita, hana mwambiha yule kijulanga, halijifanya kwa mba ye ni mswahili Hana mwambiha leo, alafu namambiha jana, alafu namambiha juzi, alafu namambiha majuzi Alafu namambiha juzi juzi, alafu namambiha majuzi yale, alafu nakijomba Siku ngavi, saba, juhu naweza kuzirudia ezo siku We mswahili, haka bakia maamakibi kama mtu waliopigwa na dafrao Kamambia tabu yako we mswahili, ni tabu ilea mfinyanzi kulia gaeni Ni nacho, ni nacho Kube huna, jina langu na hito Joram kumbi na ayuka huku ni kioseka kwenda wazimu Mpako wakati mungine, we badu wakatabahu fakiri, mekutajia siku saba Jilizopita na zijazo kiswaidi jina unaweza kuzirudia Kube huna, jina langu na hito Joram kumbi  na ayuka huku ni kioseka kwenda wazimu Mpako wakati mungine, we badu wakatabahu fakiri, mekutajia siku saba Jilizopita na zijazo kiswahili ni seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali Na ukinijibu swali hili, ba, si, sasa, nitakuingiza katika buruji la wa swahili ni seme, naa, muanetu wame kuwa Haka mwambiha sasa, e, niambihe siku saba zijazo kwa kiswahili, kila moja Alafu, uniambihe pia siku zilizo pita saba zote kwa kiswahili Alafu, baada ya pale, nitasema narotaku nisema yule mze, haka mwambiha yule kijulanga Hasa kijulanga li popigwa le swali, haka anza kutweta Hahahahahaha, anatweta, alafu haka anza kuvanga vanga Na sika na kuamba likuwa na jimasa masa, likuwa hafahamu kabisa Hameduwa kama mtu waliopigwa na dafra ho, hametuwa macho hivi Hamekutana na mze mcheke amwezi, mswahili wa mswahili, haweketi katika buruji pa mwja na kina Sherban Robert Sasa haka mwambiha, naajua haufahamu Haka mwambiha shikilia kidi nindi, nasema leo, nasema kesho, nasema kesho kutwa Nasema mtondo, mtondogo, siku ya tano yo Alafu nasema kitondo, ni siku ya sita, alafu nasema kitodyo, ni siku ya saba Kuna kitondo, siku ya sita, alafu kitodyo, siku ya saba Awu ngino nasema kitondo jogo Kamata kamatia ezo siku, saba za wiki misha kutajia zinazo kuja Zinazo pita, hana mwambiha yule kijulanga, halijifanya kwa mba ye ni mswahili Hana mwambiha leo, alafu namambiha jana, alafu namambiha juzi, alafu namambiha majuzi Alafu namambiha juzi juzi, alafu namambiha majuzi yale, alafu nakijomba Siku ngavi, saba, juhu naweza kuzirudia ezo siku We mswahili, haka bakia maamakibi kama mtu waliopigwa na dafrao Kamambia tabu yako we mswahili, ni tabu ilea mfinyanzi kulia gaeni Ni nacho, ni nacho\n",
            "\n",
            "On the day of the day, the same day of the month, the same day of the week, the same day of the year, the same Njo! And when I hear that my husband is now beating you, and if you say you're going to bring a stick and you don't have a snotty nose, you say in Kiswahili \"haka sema, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (If you don't say it, then, don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kiswahili dictionary as \"seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (Don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kiswahili dictionary as \"seme, naa, haka mwambiha, hasa keti hapo chini ni kuulize swali\" (Don't beat me, because down there is to ask a question) And when you answer this question, no, now, I will enter into the Kis\n"
          ]
        }
      ]
    }
  ]
}