{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test sortgs.py on Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaarimu/whisper_swahili/blob/main/Test_sortgs_py_on_Colab_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M36VFanosbkb"
      },
      "source": [
        "## Try `sortgs.py` on Google Colab\n",
        "This is a jupyter envirnment where you can try the code of the repository without installing anything. The only limitation is the robot checking problem which would require selenium and manual solution of the captchas, but for trying a few keywords, it should work! \n",
        "\n",
        "> **INSTRUCTIONS:** If this is the first time you are using a jupyter environment, you simply have to run the code blocks using the keyword `SHIFT` + `ENTER`. Make sure to update the keyword parameters when required. \n",
        "\n",
        "First, let's clone the repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPot8aWcsfei",
        "outputId": "0ca32440-7cf8-49ee-d78e-9049f8f1b82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/WittmannF/sort-google-scholar.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sort-google-scholar'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 244 (delta 3), reused 6 (delta 2), pack-reused 232\u001b[K\n",
            "Receiving objects: 100% (244/244), 137.39 KiB | 8.08 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM5XMRmVspR7"
      },
      "source": [
        "Now, let's open the folder from the cloned repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0mCxVNrlCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9986a4b9-f38d-4c57-dfe6-df67c5742509"
      },
      "source": [
        "cd sort-google-scholar/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sort-google-scholar/sort-google-scholar/sort-google-scholar/sort-google-scholar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KALGyCEJsvTL"
      },
      "source": [
        "Next, let's run the code. Make sure to change \"deep learning\" to the keyword that you would like to have it ranked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dohZcNUmrost",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22040ea0-7fc1-48c0-9dd7-8e80e1b1565a"
      },
      "source": [
        "# Change 'low resource languages' with the keyword that you would like to check\n",
        "!python sortgs.py --kw \"NLP for low resource languages\" --sortby \"cit/year\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading next 10 results\n",
            "Loading next 20 results\n",
            "Loading next 30 results\n",
            "Loading next 40 results\n",
            "Loading next 50 results\n",
            "Loading next 60 results\n",
            "Loading next 70 results\n",
            "Loading next 80 results\n",
            "Loading next 90 results\n",
            "Loading next 100 results\n",
            "                                        Author  ... cit/year\n",
            "Rank                                            ...         \n",
            "17     Hedderich, L Lange, H Adel, J Strötgen…  ...       32\n",
            "18                               Agic, I Vulic  ...       25\n",
            "44               Adams, A Makarucha, G Neubig…  ...       18\n",
            "8                            Şahin, M Steedman  ...       17\n",
            "62                          Strassel, J Tracey  ...       13\n",
            "...                                        ...  ...      ...\n",
            "82        Di, X Song, W Zhang, Y Zhang, F Wang  ...        0\n",
            "42                            Kryeziu, V Shehu  ...        0\n",
            "74                  Hangya, HS Saadi, A Fraser  ...        0\n",
            "77                              Agüero Torales  ...        0\n",
            "72                                       Munro  ...        0\n",
            "\n",
            "[100 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_nuxpy_s_9c"
      },
      "source": [
        "> _**NOTE:** It is normal to get some warnings, for example year not found or author not found. However, if you get the robot checking warning, then it might not work anymore in the IP that you have on Google Colab. You can try going in 'Runtime' > 'Disconnect and delete runtime' to get a new IP. If the problem persists, then you will have to run locally using selenium and solve the captchas manually. Make sure to avoid running this code too often to avoid the robot checking problem._\n",
        "\n",
        "Next, you will see that a csv file with the name of the keyword was created (which is `deep_learning.csv` in my case). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94792EoBrrBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f5536c-f7cb-4027-b1a2-9ae14bf004b2"
      },
      "source": [
        "ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mexamples\u001b[0m/                           \u001b[01;34msort-google-scholar-V1\u001b[0m/\n",
            "NLP_for_low_resource_languages.csv  \u001b[01;32msortgs.py\u001b[0m*\n",
            "README.md                           \u001b[01;34mtest\u001b[0m/\n",
            "requirements.txt                    Test_sortgs_py_on_Colab.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQIb9oYou9GM"
      },
      "source": [
        "Let's import this file to visualize some results (make sure to change `deep_learning.csv` to the file name that was created in your case):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVoHI4zTr5pB"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('NLP_for_low_resource_languages.csv') # OBS: Update the file name"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NzeUq0sOu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f0486d42-36e4-4e87-ec06-8120dfa97fc3"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Rank                                         Author  \\\n",
              "0    17        Hedderich, L Lange, H Adel, J Strötgen…   \n",
              "1    18                                  Agic, I Vulic   \n",
              "2    44                  Adams, A Makarucha, G Neubig…   \n",
              "3     8                              Şahin, M Steedman   \n",
              "4    62                             Strassel, J Tracey   \n",
              "5    22  Fesseha, S Xiong, ED Emiru, M Diallo, A Dahou   \n",
              "6     2              Magueresse, V Carles, E Heetderks   \n",
              "7    16                                              A   \n",
              "8    50          Vania, Y Kementchedjhieva, A Søgaard…   \n",
              "9    28     Ebrahimi, M Mager, A Oncevay, V Chaudhary…   \n",
              "\n",
              "                                               Title  Citations  Year  \\\n",
              "0  A survey on recent approaches for natural lang...        127  2020   \n",
              "1  JW300: A wide-coverage parallel corpus for low...        123  2019   \n",
              "2  Cross-lingual word embeddings for low-resource...        129  2017   \n",
              "3  Data augmentation via dependency tree morphing...         85  2019   \n",
              "4  Lorelei language packs: Data, tools, and resou...        102  2016   \n",
              "5  Text classification based on convolutional neu...         38  2021   \n",
              "6  Low-resource languages: A review of past work ...         50  2020   \n",
              "7  Aroma: A recursive deep learning model for opi...         77  2017   \n",
              "8  A systematic comparison of methods for low-res...         48  2019   \n",
              "9  Americasnli: Evaluating zero-shot natural lang...         30  2021   \n",
              "\n",
              "               Publisher                                      Venue  \\\n",
              "0              arxiv.org                     arXiv preprint arXiv …   \n",
              "1   repository.cam.ac.uk                                        NaN   \n",
              "2       aclanthology.org                       Proceedings of the …   \n",
              "3              arxiv.org            arXiv preprint arXiv:1903.09460   \n",
              "4       aclanthology.org   … Conference on Language Resources and …   \n",
              "5               mdpi.com                                Information   \n",
              "6              arxiv.org            arXiv preprint arXiv:2006.07264   \n",
              "7             dl.acm.org                        Resource Language …   \n",
              "8              arxiv.org                     arXiv preprint arXiv …   \n",
              "9              arxiv.org                     arXiv preprint arXiv …   \n",
              "\n",
              "                                              Source  cit/year  \n",
              "0                   https://arxiv.org/abs/2010.12309        32  \n",
              "1  https://www.repository.cam.ac.uk/bitstream/han...        25  \n",
              "2                 https://aclanthology.org/E17-1088/        18  \n",
              "3                   https://arxiv.org/abs/1903.09460        17  \n",
              "4                 https://aclanthology.org/L16-1521/        13  \n",
              "5                        https://www.mdpi.com/973660        13  \n",
              "6                   https://arxiv.org/abs/2006.07264        12  \n",
              "7         https://dl.acm.org/doi/abs/10.1145/3086575        11  \n",
              "8                   https://arxiv.org/abs/1909.02857        10  \n",
              "9                   https://arxiv.org/abs/2104.08726        10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e51a77bc-7811-4b87-a7bc-d4ac81af2ada\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Year</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Venue</th>\n",
              "      <th>Source</th>\n",
              "      <th>cit/year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>Hedderich, L Lange, H Adel, J Strötgen…</td>\n",
              "      <td>A survey on recent approaches for natural lang...</td>\n",
              "      <td>127</td>\n",
              "      <td>2020</td>\n",
              "      <td>arxiv.org</td>\n",
              "      <td>arXiv preprint arXiv …</td>\n",
              "      <td>https://arxiv.org/abs/2010.12309</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>Agic, I Vulic</td>\n",
              "      <td>JW300: A wide-coverage parallel corpus for low...</td>\n",
              "      <td>123</td>\n",
              "      <td>2019</td>\n",
              "      <td>repository.cam.ac.uk</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.repository.cam.ac.uk/bitstream/han...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>Adams, A Makarucha, G Neubig…</td>\n",
              "      <td>Cross-lingual word embeddings for low-resource...</td>\n",
              "      <td>129</td>\n",
              "      <td>2017</td>\n",
              "      <td>aclanthology.org</td>\n",
              "      <td>Proceedings of the …</td>\n",
              "      <td>https://aclanthology.org/E17-1088/</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>Şahin, M Steedman</td>\n",
              "      <td>Data augmentation via dependency tree morphing...</td>\n",
              "      <td>85</td>\n",
              "      <td>2019</td>\n",
              "      <td>arxiv.org</td>\n",
              "      <td>arXiv preprint arXiv:1903.09460</td>\n",
              "      <td>https://arxiv.org/abs/1903.09460</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>Strassel, J Tracey</td>\n",
              "      <td>Lorelei language packs: Data, tools, and resou...</td>\n",
              "      <td>102</td>\n",
              "      <td>2016</td>\n",
              "      <td>aclanthology.org</td>\n",
              "      <td>… Conference on Language Resources and …</td>\n",
              "      <td>https://aclanthology.org/L16-1521/</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>22</td>\n",
              "      <td>Fesseha, S Xiong, ED Emiru, M Diallo, A Dahou</td>\n",
              "      <td>Text classification based on convolutional neu...</td>\n",
              "      <td>38</td>\n",
              "      <td>2021</td>\n",
              "      <td>mdpi.com</td>\n",
              "      <td>Information</td>\n",
              "      <td>https://www.mdpi.com/973660</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>Magueresse, V Carles, E Heetderks</td>\n",
              "      <td>Low-resource languages: A review of past work ...</td>\n",
              "      <td>50</td>\n",
              "      <td>2020</td>\n",
              "      <td>arxiv.org</td>\n",
              "      <td>arXiv preprint arXiv:2006.07264</td>\n",
              "      <td>https://arxiv.org/abs/2006.07264</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>16</td>\n",
              "      <td>A</td>\n",
              "      <td>Aroma: A recursive deep learning model for opi...</td>\n",
              "      <td>77</td>\n",
              "      <td>2017</td>\n",
              "      <td>dl.acm.org</td>\n",
              "      <td>Resource Language …</td>\n",
              "      <td>https://dl.acm.org/doi/abs/10.1145/3086575</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>50</td>\n",
              "      <td>Vania, Y Kementchedjhieva, A Søgaard…</td>\n",
              "      <td>A systematic comparison of methods for low-res...</td>\n",
              "      <td>48</td>\n",
              "      <td>2019</td>\n",
              "      <td>arxiv.org</td>\n",
              "      <td>arXiv preprint arXiv …</td>\n",
              "      <td>https://arxiv.org/abs/1909.02857</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>28</td>\n",
              "      <td>Ebrahimi, M Mager, A Oncevay, V Chaudhary…</td>\n",
              "      <td>Americasnli: Evaluating zero-shot natural lang...</td>\n",
              "      <td>30</td>\n",
              "      <td>2021</td>\n",
              "      <td>arxiv.org</td>\n",
              "      <td>arXiv preprint arXiv …</td>\n",
              "      <td>https://arxiv.org/abs/2104.08726</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e51a77bc-7811-4b87-a7bc-d4ac81af2ada')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e51a77bc-7811-4b87-a7bc-d4ac81af2ada button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e51a77bc-7811-4b87-a7bc-d4ac81af2ada');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ZCDWaksZxj"
      },
      "source": [
        "Above we have the top 10 papers of deep learning ranked by citations per year. It is incredible that some papers are very far away from the original rank. For example, the fourth most cited paper per year is originally the number 41 in the original rank of Google! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xx5GEHuybPd"
      },
      "source": [
        "Finally, let's download the CSV results (make sure to update the CSV name here as well):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svc1GCM2yaLP",
        "outputId": "4e22ae17-cfdf-4640-d410-83ff292893b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download('NLP_for_low_resource_languages.csv') # Update the file name here"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b9ff9208-09e0-4a0e-a2c8-f2a86ad254be\", \"NLP_for_low_resource_languages.csv\", 22628)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09OFwDdM2K5h"
      },
      "source": [
        "OBS: If you get an error running the previous line, you can download the file manually by clicking in the left pane icon (below the `+ Code` button), then click in files, expand the `sort-google-scholar` folder, right click and download in the csv file:\n",
        "\n",
        "![](https://i.stack.imgur.com/KKJXFm.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM_Bb4MH14eI"
      },
      "source": [],
      "execution_count": 28,
      "outputs": []
    }
  ]
}